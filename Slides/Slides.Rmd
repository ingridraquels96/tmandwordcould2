---
title: "Mineração de dados e apresentação dos dados em nuvem de palavras"
subtitle: "Pacotes:  tm(text mining) e  wordcloud2"
author: "Bernardo Souza Scaldaferri, Denise Alves dos Santos,Ingrid Raquel Silva,  Klara Narumi de Hamada Maia"
institute: "Departamento de Estatística, Universidade Federal de Minas Gerais"
date: "Outubro de 2020"
output:
  xaringan::moon_reader:
    seal: false
    nature:
      highlightStyle: zenburn
      highlightLines: true
      slideClass: [animated,fadeIn]
    css: [default,tamu,uo-fonts,"https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css"]
    
---
class: inverse,center,middle

# Mineração de dados e Apresentação dos dados em nuvem de palavras 

## **Pacotes no R: tm(text mining) e  wordcloud2**

.right[ 

Bernardo Souza Scaldaferri

Denise Alves dos Santos

Ingrid Raquel Silva 

Klara Narumi de Hamada Maia
]

&nbsp;
<center><font size="5">Universidade Federal de Minas Gerais </font></center>

???
Comentário: 
A capa desse trabalho não foi gerada automática, já que foi feito uma capa personalizada.

---
# Motivação
- Grande volume de informações em formato de texto na internet;
- Extrair informações de forma automática e com diminuição de vieses

&nbsp;
--

# Conceito Básico
- Análogo ao Data Mining é o processo de extração de informações a partir de textos no geral.

???
Comentário:

Um grande volume de informações disponíveis na internet estão em formato de texto, em jornais, blog ou redes sociais, como o Twitter ou o Facebook.

O Text Mining permite a automatização de boa parte do processo de coleta e análise desses dados, reduzindo assim os vieses gerados pela intervenção humana e permitindo o rápido processamento de um grande volume de textos.

---
# Quais tipos de análise são possíveis em um Text Mining? 

--

- Sumarização 

--

- Categorização

--

- Clustering

--

- Análise de Sentimentos 

???
Comentário:

O Text Mining trabalha com diversos tipos de análises, exemplos de algumas delas: Sumarização, um resumo das informações relevantes encontradas e depois coloca-se em formato de sumário, Categorização, uma separação por categorias dessas informações, Clustering, um processo que busca agrupar as informações por semelhança, e Análise de Sentimentos, conjunto de técnicas computacionais que buscam os sentimentos expressos pelo autor quando ele se refere a coisas específicas no texto (fatos, pessoas, lugares, etc), no geral com o objeto de se identificar o viés.

---
class: inverse, center, middle, animated, slideInRight

# Pacotes que vão ser utilizados durante o processo
.left[
- tidyverse
- wordcloud2
- tm
- tidytext
- pdftools
- rvest
- readr
]

---
class: animated, slideInRight

# Coleta
- Precisa-se transformar em matriz e posteriormente em vetor;
- Como base de dados usa-se vários formatos, nesse caso usou-se pdf e txt;
- Dividi-se o texto para transformar em data frame e depois em matriz;
- Para apresentação deste trabalho escolheu-se análise discurso Ulysses Guimarães.

```{r definindo o diretório de trabalho, echo=FALSE, results = "hide"}
getwd() 

rm(list = ls(all=T))
options(scipen=999)
```

```{r instala_pacotes, message=FALSE, warning=FALSE,echo=FALSE,results = "hide"}
listofPackages <- c("tidyverse","wordcloud2", "tm", "tidytext", "pdftools", "rvest", "readr") 
```

```{r função instalar/chamar pacotes, message=FALSE, warning=FALSE, include=FALSE,results = "hide"}
packages <- function(listofPackages){
  new.packages <- listofPackages[!(listofPackages %in% installed.packages()[, "Package"])]
  if (length(new.packages))
    install.packages(new.packages, dependencies = TRUE)
  sapply(listofPackages, require, character.only = TRUE)
}

lapply(listofPackages, library, character.only = TRUE)
```

### Etapas da Coleta:

1- Baixar o arquivo pdf 

2- Importar o arquivo pdf
```{r importar o arquivo pdf, results = "hide"}
pdf_info("Ulysses_Constituinte.pdf")
ulysses <- pdf_text("Ulysses_Constituinte.pdf")
```

3- Separar a parte com o conteúdo do discurso
```{r separar a parte com o conteúdo do discurso}
ulysses <- ulysses[c(1,2)]
ulysses <- paste(ulysses, collapse = " ")
```

???
Comentário:

Primeiro, coleta-se os dados,  a base de dados pode ser estática ou dinâmica, caso  seja dinâmica, o formato rmarkdown é preferível e pode-se consegui-las através do Machine Learning,  vários formatos de arquivos são aceitos, como txt, pdf e csv, também é possível extrair textos diretamente da internet usando o rvest, especialmente útil para notícias. Os dados extraídos serão transformados em uma Matriz que será subdividida, facilitando o seu processamento e exclusão de informações desnecessárias.

Etapas da coleta (nesse caso faremos uma análise de um base estática Discurso de Ulysse Guimarães no dia da promulgação da constituição)

---
class: animated, slideInRight

# Dicas: 

- Grave o arquivo em formato txt
```{r grava o arquivo em formato txt}
write_lines(ulysses, "ulysses.txt")
```

- Selecione o discurso
```{r selecionando o discurso, warning=FALSE, message=FALSE}
texto <- read_csv("ulysses.txt", col_names = FALSE) 
novo_texto <- texto[11,1] 
```

- Converta em vetor
```{r convertendo em vetor}
novo_texto <- as.matrix(novo_texto)
novo_texto <- as.vector(novo_texto)
```

- Retire uma referência
```{r re, warning=FALSE, message=FALSE, results = "hide"}
novo_texto <- str_replace(novo_texto, "https://www.camara.leg.br/radio/programas/277285-integra-do-discurs…nte-da-assembleia-nacional-constituinte-dr-ulysses-guimaraes-10-23/        Página 1 de 3
 Portal da Câmara dos Deputados                                                                                                               02/10/2020 23'15", "")
write_lines(novo_texto, "ulysses.txt")
novo_texto # retirado
```

---
class: animated, slideInRight

4- Partir o discurso em unidades textuais, divida por linhas
```{r, warning=FALSE, message=FALSE, results = "hide"}
novo_origem <- read_lines("ulysses.txt") 
str(novo_origem)
```

```{r, warning=FALSE, message=FALSE, results = "hide"}
dez <- rep(1:ceiling(length(novo_origem)/10), each = 10)
str(dez)
```

```{r, warning=FALSE, message=FALSE, results = "hide"}
dez <- dez[1:length(novo_origem)]
str(dez)
```

```{r, warning=FALSE, message=FALSE, results = "hide"}
novo_texto <- cbind(dez, novo_origem) %>% data.frame()

novo_texto <- aggregate(formula = novo_origem ~ dez,
                        data = novo_texto,
                        FUN = paste,
                        collapse = " ")

novo_texto <- novo_texto %>% select(novo_origem) %>% as.matrix
dim(novo_texto)
```

---
class: animated, slideInRight

# Pré-processamento
Uma forma de preparar o texto, isto é, deixa-lo apto para os próximos passos da mineração envolve os seguinte passos:

## O pacote tm 

- Eliminar caracteres especiais;
```{r}
novo_texto <- gsub("[[:cntrl:]]", " ", novo_texto) 
```

- Deixar tudo minúsculo;
```{r}
novo_texto <- tolower(novo_texto)
```

- Remove pontuação
```{r}
novo_texto <- removePunctuation(novo_texto) 
```

---
class: animated, slideInRight

- Retirada das chamadas stopwords
```{r stopwords, results = "hide"}
#Carregando o stopwords do pacote tm
sw_pt_tm <- stopwords('portuguese')
#Convertendo para dataframe
sw_pt_tm <- data.frame(sw_pt_tm)
#Renomeando a variável
sw_pt_tm <- rename(sw_pt_tm, palavra = sw_pt_tm)

stopwords_personal <- tibble(palavra = c("é", "ainda", "alguns", "pra"))

#stop_words_pt <- c(stopwords("pt"), "é", "ainda", "alguns", "pra")
```

```{r}
novo_texto <- removeWords(novo_texto, stopwords("pt"))
# novo_texto <- removeWords(novo_texto, stop_words_pt)
```

- Remover os espaços em branco;
```{r}
novo_texto <- stripWhitespace(novo_texto)
```

- Stemming, deixar apenas o radical para eliminar plurais, masculino ou feminino e pequenas variações.

???
Comentário:

Stopwords são palavras previamente selecionadas que não agregam informações à análise, como conectivos, vícios de linguagem, por exemplo, o, a é, algum. 
Pode ser personalizado, mas o pacote tm tem stopwords em português)

---
class: animated, slideInRight

### Agora renomear a variável

```{r}
novo_texto <- tibble(texto = novo_texto) 
```

### Depois

- Tokenizar as palavras e eliminar as palavras de conexão
```{r eliminando stopwords, warning=FALSE, message=FALSE, esults = "hide"}
texto_palavras <- novo_texto %>% 
  unnest_tokens(palavra, texto, strip_numeric = TRUE) %>% 
  count(palavra, sort = TRUE)
palavras_freq <- texto_palavras %>% 
  anti_join(stopwords_personal) %>%
  anti_join(sw_pt_tm)
```

---
class: animated, slideInRight

# Indexação

Nessa etapa cria-se um identificador (índice) para cada palavra, dessa forma pode-se acessar com facilidade as informações;

- Palavras frequentes
```{r,  warning=FALSE, message=FALSE, results = "hide"}
grafico_palavras <- palavras_freq %>% 
  top_n(10) %>% 
  ggplot(aes(y = reorder(palavra, n), x = n)) + 
  geom_col(fill = "#EEBBAA") +labs(y = NULL, x = "frequencia",
  title = "As 10 palavras mais frequentes") + theme_minimal()
```

```{r, echo = FALSE, fig.align="center", fig.height=3.5, fig.width=7}
grafico_palavras
```

---
class: animated, slideInRight

# Nuvem de palavras
```{r, results="hide"}
wordcloud2(data = palavras_freq, size = 0.3)
```

<center>
```{r, echo = FALSE}
wordcloud2(data = palavras_freq, size = 0.3)
```
</center>

---
## Argumentos nuvem de palavras worcloud2

.pull-left[
- data
- size
- minSize
- gridSize
- fontFamily
- fontWeight
- color
- backgroundColor
- minRotation
- maxRotation
- shuffle
- rotateRatio
]

--
.pull-right[

- shape:
  - circle
  - cardioid
  - diamond
  - triangle-forward
  - triangle
  - pentagon
  - star
- ellipticity
- widgetsize
- figPath
- hoverFunction
]

---
class: animated, slideInRight

# Mineração

- Extração de informações relevantes, da parte mais “refinada”.

- Essa parte geralmente usa algoritmos de Machine Learning para ser feita;

- Nesse contexto usou-se método euclidiano de distância. 
```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_texto <- as.matrix(novo_texto)
novo_texto <- as.vector(novo_texto)
novo_texto 
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
corpus_source <- VectorSource(novo_texto)
novo_corpus <- Corpus(corpus_source)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_tdm <- TermDocumentMatrix(novo_corpus)
novo_tdm 
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
findAssocs(novo_tdm, "constituição", 0.7) 

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
findAssocs(novo_tdm, terms = c("sociedade", "nação", "estado"), corlimit = .70)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
inspect(removeSparseTerms(novo_tdm, 0.4))
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_new <- removeSparseTerms(novo_tdm, sparse = .75)

novo_tdm 

novo_new 
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_tdm$nrow 
novo_new$nrow 
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_new <- novo_new %>% as.matrix()
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_new <- novo_new / rowSums(novo_new)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}
novo_dist <- dist(novo_new, method = "euclidian")
```

???
Comentário:

Na análise feita usou-se método Euclidiano de distâncias a fim de “medir” quais palavras estavam mais próximas, para isso criou-se uma matriz de distâncias;

---
class: middle, animated, slideInRight

```{r, warning=FALSE, message=FALSE, results = "hide"}
novo_hclust <-  hclust(novo_dist, method = "ward.D")
plot(novo_hclust, main = "Dendrograma do discurso - hclust",
     sub = "", xlab = "")
rect.hclust(novo_hclust, k = 5, border="blue")
```

```{r,echo=FALSE}
novo_hclust <-  hclust(novo_dist, method = "ward.D")
plot(novo_hclust, main = "Dendrograma do discurso - hclust", sub = "", xlab = "")
rect.hclust(novo_hclust, k = 5, border="blue")
```

???
Comentário:

Análise

Há várias metodologias para Mineração e Análise (como as anteriormente que giram em torno de separar tudo e agrupar por semelhanças), nesse contexto, usou-se matrizes de distâncias com método euclidiano de distância (há outros tipos de distâncias), depois utilizou-se das distâncias para realizar um agrupamento hierárquico entre as palavras e depois plotar um dendograma e pode-se observar quais palavras e estão correlacionadas de alguma forma.

Análise humana. Leitura e interpretação de dados
O discurso de Ulysses Guimarães por ocasião da promulgação da Constituição ocorre após mais de 21 anos de ditadura de regime militar. Também é o resultado de muitos debates públicos

A palavra "Constituição" vem acompanhada de apalusos (aqui a transcrição menciona a reação dos deputados constituintes). São frequentemente citadas as palavras: Sociedade, Nação e Estado.

As associações de palavra apresentam a palavra constituição em associação de 77% com vários substantivos como: amor, analfabetos, cidadania, hospital, população. 

Algo que apresenta uma análise interessante são as palavras nação e estado. Muitas vezes são usada como sinônimas. Ulysses Guimarães em seu discurso as emprega de modo distinto.
 
A análise mostra que, ao falar de nação, são palavras majoritariamente de orientação positiva: mudar, amor, cidadania, execução, restauração, remédio.

Ao se referir ao Estado é possível constatar um inflexão mais negativa: capitulou, entregou, nomeia inssurreições ocorridas em passado recente e remoto: Acre, Guararapes, cita facínoras, e também pessoas torturadas e mortas pelo regime militar. O Estado na referência de Ulysses Guimarães é violento.

Com a métrica das palavras é possível fazer um dendograma de associação das palavras.

Um primeiro núcleo está a sociedade e o estado que está associado a uma mudança de ser.
Um outro cluster bastante interessante agrupa o Brasil com a questão da moral pública perfeita.

O terceiro cluster coloca a democracia em relação com a pátria e o parlamento e as leis com as reivindicações (que vêm da participação popular - democracia)

A figura do homem como responsável pela elaboração da Constituinte.

O último cluster coloca a constituição como palavras que devem mudar a nação. Neste cluster que estão alocados os aplausos transcritos no texto como reação dos parlamentares presentes.

---
class:   animated, slideInRight

# Referências

- https://www.curso-r.com/material/stringr/
- https://rdrr.io/rforge/tm/ 
- https://rpubs.com/tsholliger/301914
- https://www.learningrfordatascience.com/post/dynamic-wordclouds-with-wordcloud2/
- https://p4husp.github.io/material/textmining/ 
- https://p4husp.github.io/material/tutorial11/ 
- https://www.r-graph-gallery.com/196-the-wordcloud2-library.html
- https://cran.r-project.org/web/packages/wordcloud2/wordcloud2.pdf

---
class: center, middle, animated, slideInDown

# Muito obrigada
![](https://media.giphy.com/media/MDJ9IbxxvDUQM/giphy.gif)